{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad991fe9",
   "metadata": {},
   "source": [
    "# OpenAI SDK Agent\n",
    "We will use openai-sdk-agents to create simple AI agents\n",
    "\n",
    "Learn more about them in https://github.com/openai/openai-agents-python\n",
    "\n",
    "Documentation: https://openai.github.io/openai-agents-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618f338d",
   "metadata": {},
   "source": [
    "## Create .env file\n",
    "- Create a .env file in your working directory\n",
    "- Sign up in openai platform https://auth.openai.com/log-in\n",
    "- Get the free tier API key from OPENAI, https://platform.openai.com/account/api-keys\n",
    "- Add the key in .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI_API_KEY=\"your_openai_api_key_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a9d59e",
   "metadata": {},
   "source": [
    "## Load environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45101b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables from a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e9f285",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the agents library import necessary components\n",
    "from agents import Agent, Runner, trace\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cee4b5",
   "metadata": {},
   "source": [
    "## Create a basic Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1278122",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make an basic agent with name, instructions and model\n",
    "# Other models from openai are gpt-4.1-mini.\n",
    "# Find more on https://auth.openai.com/log-in\n",
    "gpt_agent = Agent(name=\"Jokester\", \n",
    "                instructions=\"You are a joke teller\", \n",
    "                model=\"gpt-4.1-nano\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215632ff",
   "metadata": {},
   "source": [
    "## Run Agent in non streaming mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59931a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Runner.run(agent, prompt) is non streaming mode of running agent\n",
    "# Since it is an async function, we need to use 'await' to call it\n",
    "query = \"Tell a joke about Software engineer who is an Autonomous AI Agents\"\n",
    "result = await Runner.run(gpt_agent, query)\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5969da",
   "metadata": {},
   "source": [
    "Logs can be traced at https://platform.openai.com/traces\n",
    "\n",
    "Default trace name would be \"Agent workflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5cd0ce",
   "metadata": {},
   "source": [
    "## Use custom trace name\n",
    "\n",
    "You can use with statement to give a custom name to trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7456109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trace(\"Telling a joke\"):\n",
    "    result = await Runner.run(gpt_agent, query)\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753c3e6d",
   "metadata": {},
   "source": [
    "## Use trace id\n",
    "\n",
    "Alternatively, you can generate a trace id and use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import gen_trace_id\n",
    "\n",
    "trace_id = gen_trace_id()\n",
    "print(f\"Trace link: https://platform.openai.com/logs/trace?trace_id={trace_id}\\n\\n\")\n",
    "\n",
    "with trace(\"Telling a joke\", trace_id=trace_id):\n",
    "    result = await Runner.run(gpt_agent, query)\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3470bfb3",
   "metadata": {},
   "source": [
    "From now on, to avoid lengthy code, we will not use custom trace id. We will use openAI default traces.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf6154",
   "metadata": {},
   "source": [
    "## Run agent in Streaming mode\n",
    "\n",
    "Read more at https://openai.github.io/openai-agents-python/streaming/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abedf898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Runner.run_streamed(agent, prompt) to run the agent in streaming mode\n",
    "# Since it is an async function, we need to use 'await' to call it\n",
    "# Iterate over the events from result.stream_events()\n",
    "# For each event, if it is of type \"raw_response_event\" and its data is\n",
    "# an instance of ResponseTextDeltaEvent, print the delta text as it arrives\n",
    "# This will print the response in a streaming fashion\n",
    "\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "\n",
    "gpt_agent = Agent(name=\"Clinical Expert\", \n",
    "                instructions=\"You are a clinical expert in genetics\", \n",
    "                model=\"gpt-4.1-nano\")\n",
    "\n",
    "query = \"Tell me about ACMG classification of genetic variants\"\n",
    "result = Runner.run_streamed(gpt_agent, query)\n",
    "\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "        print(event.data.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c367276",
   "metadata": {},
   "source": [
    "From now on we will use non streaming mode for simplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ec38cd",
   "metadata": {},
   "source": [
    "## Interact with Agent with a chat interface\n",
    "We can use Gradio chat for simple chat interface. \n",
    "\n",
    "Know more about Gradio at: https://www.gradio.app/\n",
    "\n",
    "ChatInterface: https://www.gradio.app/docs/gradio/chatinterface\n",
    "\n",
    "\n",
    "- Define chat function for Gradio interface\n",
    "- Chat function takes message and history as input\n",
    "- Pass history as context to the agent along with the message\n",
    "- Get the final output from the agent's response\n",
    "\n",
    "The below chat interface function won't have history. You have to explicitely pass message and history as query to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99253ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(message, history):\n",
    "    # Uncomment below line to make chat interface know history\n",
    "    # But better to use sqlite session for that\n",
    "    # message = message + \"Context: \" + str(history)\n",
    "    result = await Runner.run(gpt_agent, message)\n",
    "    return result.final_output\n",
    "\n",
    "import gradio as gr\n",
    "gr.ChatInterface(\n",
    "    chat,\n",
    "    title=\"Clinical Expert Chatbot\",\n",
    "    description=\"Chat with the Clinical Expert\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a9bfa",
   "metadata": {},
   "source": [
    "## Use session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import SQLiteSession\n",
    "\n",
    "# In memory session. This will not persist across restarts\n",
    "session = SQLiteSession(\"my_session\")\n",
    "\n",
    "# Alternatively, you can use a file based session. This will persist across restarts\n",
    "# session = SQLiteSession(\"my_session\", \"./my_session.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618aaefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(message, history):\n",
    "    result = await Runner.run(gpt_agent, message, session=session)\n",
    "    return result.final_output\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "gr.ChatInterface(\n",
    "    chat,\n",
    "    title=\"Clinical Expert Chatbot\",\n",
    "    description=\"Chat with the Clinical Expert\"\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213721fc",
   "metadata": {},
   "source": [
    "## Provide tools to agent\n",
    "\n",
    "So far AI agents were linked with LLM models. Now we empower them with tools.\n",
    "\n",
    "- Write a simple python function\n",
    "- Provide docstring\n",
    "- Decorate with @function_tool decorator\n",
    "\n",
    "This way any python function is converted to Agent Tool.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228c5e1",
   "metadata": {},
   "source": [
    "#### Define Tools\n",
    "\n",
    "We will define a function calculate_n_content, it returns total N bases + 10. Just to check agent uses tools. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23995a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import function_tool\n",
    "\n",
    "@function_tool\n",
    "def calculate_n_content(dna_sequence: str) -> float:\n",
    "    \"\"\"Use this tool to calculate total N bases in a DNA sequence. \n",
    "    This is a custom tool which adds 10 to the N count.\n",
    "    \"\"\"\n",
    "    n_count = dna_sequence.upper().count('N')\n",
    "    return n_count+10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424fa781",
   "metadata": {},
   "source": [
    "#### Define Agent\n",
    "\n",
    "For tool calling, use some good model like gpt-4.1-mini which supports tool calling.\n",
    "https://platform.openai.com/docs/models/gpt-4.1-mini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_instructions = \"\"\"You are a helpful assistant for Bioinformatics task. \n",
    "You are equipped with calculate_n_content tool. \n",
    "If query involves DNA sequence N content analysis, you must use this tool to calculate N content. Otherwise chat normally.\n",
    "\"\"\"\n",
    "\n",
    "bioinfo_agent = Agent(name=\"BioinformaticsAgent\",\n",
    "                    instructions=agent_instructions,\n",
    "                    model=\"gpt-4.1-mini\",\n",
    "                    tools=[calculate_n_content])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056126f3",
   "metadata": {},
   "source": [
    "#### Run the Agent in a chat interface with session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = SQLiteSession(\"bioinfo_session\")\n",
    "\n",
    "async def chat(message, history):\n",
    "    result = await Runner.run(bioinfo_agent, message, session=session)\n",
    "    return result.final_output\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "gr.ChatInterface(\n",
    "    chat,\n",
    "    title=\"Bioinformatics Expert Chatbot\",\n",
    "    description=\"Chat with the Bioinformatics Expert\"\n",
    ").launch()\n",
    "\n",
    "# You can ask below question to test the tool\n",
    "# query = \"N content in dna: ATGNNNATG\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
