{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad991fe9",
   "metadata": {},
   "source": [
    "### Chat with your LinkedIn Profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the agents library import necessary components\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace, SQLiteSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9c3464",
   "metadata": {},
   "source": [
    "#### Load environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45101b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab624a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "from openai import AsyncOpenAI\n",
    "from agents import OpenAIChatCompletionsModel\n",
    "import os\n",
    "\n",
    "# Define the OpenAI client pointing to a local LLM server\n",
    "client = AsyncOpenAI(base_url=\"http://localhost:11434/v1\")\n",
    "\n",
    "# Define model using the local LLM server client\n",
    "# thinking mode: gpt-oss. takes time\n",
    "model = OpenAIChatCompletionsModel(model = \"llama3.2:latest\",openai_client= client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ea538",
   "metadata": {},
   "source": [
    "#### Read Linkedin PDF to text\n",
    "\n",
    "Parsing linkedin PDF to text and creating system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b117d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"me.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "\n",
    "with open(\"summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "name=\"Priyabrata\"\n",
    "\n",
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n",
    "\n",
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df3e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Agent\n",
    "# Create an agent using the local model\n",
    "local_agent = Agent(name=\"LinkedInAgent\",\n",
    "                    instructions=system_prompt,\n",
    "                    model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf1c030",
   "metadata": {},
   "source": [
    "### Gradio chat app with local llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a9537",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = SQLiteSession(\"linkedin_agent_session.db\")\n",
    "\n",
    "async def chat(message, history):\n",
    "    result = await Runner.run(local_agent, message, session=session)\n",
    "    return result.final_output\n",
    "\n",
    "import gradio as gr\n",
    "gr.ChatInterface(\n",
    "    chat,\n",
    "    title=\"Priyabrata LinkedIn Agent\",\n",
    "    description=\"Chat with Priyabrata's LinkedIn agent.\"\n",
    ").launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
